{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90784331",
   "metadata": {},
   "source": [
    "## CSCI 347 Project 2\n",
    "Philip Ghede and Moiyad Alfawwar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a3c70",
   "metadata": {},
   "source": [
    "## Part1: Think about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a1300",
   "metadata": {},
   "source": [
    "- Why are you interested in this data set?\n",
    "- Clearly state if/how the data was pre-processed (Was the largest connected com-\n",
    "ponent extracted? Was a sample of vertices or edges taken? If so, describe the sampling\n",
    "process that was used.)?\n",
    "- Before doing any analysis, answer the question. What characteristics do you expect\n",
    "the vertices with high centrality values to have and why? Specifically, think about non-graph\n",
    "characteristics. For example, in a graph where nodes represent cities and edges are roads\n",
    "between them, we might expect highly central cities to have high populations or to house\n",
    "major industries.\n",
    "\n",
    "*Paragraph needs to be written here about the data addressing the above questions*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e87cc6",
   "metadata": {},
   "source": [
    "## Part2: Write Python code for graph analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9de53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "# import csv\n",
    "# !pip install scipy\n",
    "from scipy import *\n",
    "\n",
    "\n",
    "# # read data from the csv file\n",
    "# def read_dat()\n",
    "\n",
    "# 2.1 Function to determine number of vertices in a graph\n",
    "def number_of_vertices(graph):\n",
    "    # tuples to list\n",
    "    my_list = [item for x in graph for item in x]\n",
    "    # remove duplicates\n",
    "    unique_set = set(my_list)\n",
    "    counter = len(unique_set)\n",
    "    return counter\n",
    "\n",
    "\n",
    "# 2.2 Function for finding the degree of a vertex\n",
    "def degrees_of_vertex(graph, vertex):\n",
    "    # Converting tuples to list\n",
    "    my_list = [item for x in graph for item in x]\n",
    "    counter = 0\n",
    "    for i in my_list:\n",
    "        if i == vertex:\n",
    "            counter = counter + 1\n",
    "    return counter\n",
    "\n",
    "# Helper function: Get number of edges from subgraph\n",
    "def subgraph_edges(graph, vertices):\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(graph)\n",
    "    induced_subgraph = G.subgraph(vertices)\n",
    "    number_of_edges = nx.number_of_edges(induced_subgraph)\n",
    "    return number_of_edges\n",
    "\n",
    "\n",
    "# Helper function: Generate edges_list in graph\n",
    "def generate_graph(edges):\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    return G\n",
    "\n",
    "# Function for finding the clustering coefficient of a vertex\n",
    "# ref: https://www.geeksforgeeks.org/python-find-the-tuples-containing-the-given-element-from-a-list-of-tuples/1\n",
    "def clustering_coefficient(graph, vertex):\n",
    "    # Obtains a list of all the neighbors of the given vertex\n",
    "    filtered_list = list(filter(lambda x: vertex in x, graph))\n",
    "    # Converts the list of tuples into a regular list\n",
    "    regular_list = [item for x in filtered_list for item in x]\n",
    "    # Remove the vertex value from the regular list to get the list of just the neighbors\n",
    "    neighbors = list(filter(vertex.__ne__, regular_list))\n",
    "    # Calls a helper function that generates a graph from the edge list and creates a subgraph\n",
    "    # of neighbors and then finds the number of edges amongst the subgraph of neighbors\n",
    "    total_edges_actual = subgraph_edges(neighbors, graph)\n",
    "    # Gets the number of neighbors\n",
    "    number_of_neighbors = len(neighbors)\n",
    "    # Calculates the number of total edges possible by (n-1)*(n/2) where n is the number of vertices\n",
    "    total_edges_possible = (number_of_neighbors - 1) * (number_of_neighbors / 2)\n",
    "    # Calculates the clustering coefficient by dividing\n",
    "    # the number of actual edges by the total number of possible edges\n",
    "    clustering_coefficient = total_edges_actual / total_edges_possible\n",
    "    return clustering_coefficient\n",
    "\n",
    "# Function for finding the betweenness centrality of a vertex\n",
    "def betweenness_centrality(edgelist, vertex):\n",
    "    values = []\n",
    "    betweenness = 0\n",
    "    size = number_of_vertices(edgelist)\n",
    "    # Generate a graph from the given edgelist using a helper function\n",
    "    graph = generate_graph(edgelist)\n",
    "\n",
    "    # To determine if edgelist starts with 0 vs 1\n",
    "    if edgelist[0][0] == 1:\n",
    "        vertex_list = list(range(1, 1 + size))\n",
    "    else:\n",
    "        vertex_list = list(range(0, size))\n",
    "\n",
    "    # Removes the specified vertex from the vertex list since it\n",
    "    # won't be used in making a list of all possible vertex pairs\n",
    "    vertex_list.remove(vertex)\n",
    "\n",
    "    # Create a list of all the vertex pairs excluding x,x pairs (i.e. 1,1 or 2,2 etc.)\n",
    "    for s in range(len(vertex_list)):\n",
    "        for t in range(len(vertex_list)):\n",
    "            if s != t:\n",
    "                values = values + [[vertex_list[s], vertex_list[t]]]\n",
    "\n",
    "    # Get rid of mirrored duplicates (i.e. [[0,1],[1,0]] -> [[0,1]])\n",
    "    s = set()\n",
    "    out = []\n",
    "    for i in values:\n",
    "        t = tuple(i)\n",
    "        if t in s or tuple(reversed(t)) in s:\n",
    "            continue\n",
    "        s.add(t)\n",
    "        out.append(i)\n",
    "\n",
    "    # Extract the columns from the nested list so we have a list of every\n",
    "    # possible node pair with no repeats and no x, x node pairs\n",
    "    x_bar = [i[0] for i in out]\n",
    "    y_bar = [i[1] for i in out]\n",
    "\n",
    "    # Simultaneously iterate through the separate columns representing all vertex pairs and find all shortest paths\n",
    "    for (x, y) in zip(x_bar, y_bar):\n",
    "        count = 0\n",
    "\n",
    "        # Get a list of all the shortest paths for every pair of nodes\n",
    "        list_shortest_paths = list([p for p in nx.all_shortest_paths(graph, source=x, target=y)])\n",
    "\n",
    "        # Get the total number of shortest paths\n",
    "        number_of_shortest_path = len(list_shortest_paths)\n",
    "\n",
    "        # Flatten the nested list into a list of single elements\n",
    "        flat_list = [item for sublist in list_shortest_paths for item in sublist]\n",
    "\n",
    "        # Search for the number of occurrences of the betweenness node\n",
    "        for i in flat_list:\n",
    "            if i == vertex:\n",
    "                count = count + 1\n",
    "\n",
    "        # Calculate betweenness centrality\n",
    "        betweenness = betweenness + (count / number_of_shortest_path)\n",
    "    return betweenness\n",
    "\n",
    "\n",
    "def adj_matrix(graph):\n",
    "    vertices = number_of_vertices(graph)\n",
    "    # Initilize empty array\n",
    "    matrix_array = np.zeros((vertices, vertices))\n",
    "    # Use the vertices as coordinate to iterate thru the array\n",
    "    x_part = [i[0]-1 for i in graph]\n",
    "    y_part = [i[1]-1 for i in graph]\n",
    "\n",
    "    # modifies the matrix.\n",
    "    for (x, y) in zip(x_part, y_part):\n",
    "        matrix_array[x][y] = 1\n",
    "        matrix_array[y][x] = 1\n",
    "    return matrix_array\n",
    "\n",
    "\n",
    "def prestiege_centrality(matrix_arrr):\n",
    "    current_vector = np.ones(len(matrix_arrr))\n",
    "    previous_vector = np.ones(len(matrix_arrr))\n",
    "    result = np.ones(len(matrix_arrr))\n",
    "    for i in range(100):\n",
    "        previous_vector = current_vector\n",
    "        current_vector = np.dot(matrix_arrr, previous_vector)\n",
    "        result = np.dot(current_vector, (1/np.linalg.norm(current_vector, 2)))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e71264",
   "metadata": {},
   "source": [
    "## Part 3: Analyze the graph data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af0968",
   "metadata": {},
   "source": [
    "1. Produce a visualization of the graph (or graph sample that you used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b79392",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"data\\lastfm_asia_edges.csv\", delimiter=\",\")\n",
    "nx.draw_networkx(G, with_labels=False, node_size=100, edgecolors=\"#202020\", alpha=0.7)\n",
    "# G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8874b4d",
   "metadata": {},
   "source": [
    "2. Find the 10 nodes with the highest degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "061d4a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7237', 216),\n",
       " ('3530', 175),\n",
       " ('4785', 174),\n",
       " ('524', 172),\n",
       " ('3450', 159),\n",
       " ('2510', 140),\n",
       " ('3597', 124),\n",
       " ('2854', 119),\n",
       " ('6101', 119),\n",
       " ('5127', 119)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(nx.degree(G), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f707d0",
   "metadata": {},
   "source": [
    "3. Find the 10 nodes with the highest betweenness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982d197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7199': 0.08993132921587156,\n",
       " '7237': 0.08558851292049027,\n",
       " '2854': 0.077563011903684,\n",
       " '4356': 0.06724977863524628,\n",
       " '6101': 0.051804797126635244,\n",
       " '5454': 0.043613830289128734,\n",
       " '4338': 0.04289874773767917,\n",
       " '5127': 0.038412349470904675,\n",
       " '3450': 0.036932802520032906,\n",
       " '4785': 0.034960797890157956}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_betweenness_cent = {k: v for k, v in sorted(nx.betweenness_centrality(G).items(), key=lambda item: item[1], reverse=True)}\n",
    "{k:v for (k,v) in [x for x in highest_betweenness_cent.items()][:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859fc54",
   "metadata": {},
   "source": [
    "4. Find the 10 nodes with the highest clustering coefficient. If there are ties, choose 10 to report and explain how the 10 were chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85ed067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'12': 1.0,\n",
       " '2625': 1.0,\n",
       " '3740': 1.0,\n",
       " '2301': 1.0,\n",
       " '3562': 1.0,\n",
       " '42': 1.0,\n",
       " '46': 1.0,\n",
       " '5195': 1.0,\n",
       " '5474': 1.0,\n",
       " '3008': 1.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_clustering = {k: v for k, v in sorted(nx.clustering(G).items(), key=lambda item: item[1], reverse=True)}\n",
    "{k:v for (k,v) in [x for x in highest_clustering.items()][:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ebaf6",
   "metadata": {},
   "source": [
    "5. Find the top 10 nodes as ranked by prestige centrality (eigenvector centrality in networkx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55abac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7237': 0.256134231102378,\n",
       " '3240': 0.19657824079541275,\n",
       " '3597': 0.19082938528653803,\n",
       " '763': 0.18168465975492687,\n",
       " '378': 0.16424646725239936,\n",
       " '2083': 0.16272123075395906,\n",
       " '1334': 0.1625309135128099,\n",
       " '3544': 0.151873662868128,\n",
       " '4809': 0.1512824322578676,\n",
       " '2734': 0.1464879585121097}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_prestige_cent = {k: v for k, v in sorted(nx.eigenvector_centrality(G).items(), key=lambda item: item[1], reverse=True)}\n",
    "{k:v for (k,v) in [x for x in highest_prestige_cent.items()][:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a165df3",
   "metadata": {},
   "source": [
    "6. Find the top 10 nodes as ranked by Pagerank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba254ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4811': 0.0034207101040038806,\n",
       " '4785': 0.003261332771883333,\n",
       " '3530': 0.0027190464788557044,\n",
       " '7237': 0.0025805027648334988,\n",
       " '3450': 0.002431449702413466,\n",
       " '2854': 0.0023561637916072954,\n",
       " '2510': 0.0023172590563457153,\n",
       " '524': 0.001966829068839528,\n",
       " '5127': 0.0018858456199523778,\n",
       " '6101': 0.0017762813264083851}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_pgrank = {k: v for k, v in sorted(nx.pagerank(G).items(), key=lambda item: item[1], reverse=True)}\n",
    "{k:v for (k,v) in [x for x in highest_pgrank.items()][:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54839df3",
   "metadata": {},
   "source": [
    "7. (3 points) Comment on the differences and similarities in questions Part 3 1-6. Are the highly ranked nodes mostly the same? Do you notice significant differences in the rankings? Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a59ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
